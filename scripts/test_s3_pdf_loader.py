#!/usr/bin/env python3
"""
S3 PDF ë¡œë” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    # S3 ì„¤ì • í™•ì¸
    python scripts/test_s3_pdf_loader.py --check-config

    # S3ì—ì„œ PDF ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ S3 íŒŒì¼ í•„ìš”)
    python scripts/test_s3_pdf_loader.py --load-pdf --s3-key "test123/resume.pdf"

    # êµ¬ì§ì ë¶„ì„ E2E í…ŒìŠ¤íŠ¸ (S3 PDF)
    python scripts/test_s3_pdf_loader.py --analyze --s3-key "test123/resume.pdf" -o result.json

í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ (.env):
    GOOGLE_API_KEY=xxx
    S3_BUCKET_NAME=xxx
    S3_REGION=ap-northeast-2
    AWS_ACCESS_KEY_ID=xxx (ë˜ëŠ” IAM Role)
    AWS_SECRET_ACCESS_KEY=xxx (ë˜ëŠ” IAM Role)
"""

import argparse
import asyncio
import json
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
load_dotenv()


def check_config():
    """ì„¤ì • í™•ì¸"""
    from langchain_pipeline.config import validate_config

    print("\n" + "=" * 60)
    print("ğŸ”§ S3 PDF ë¡œë” ì„¤ì • í™•ì¸")
    print("=" * 60)

    result = validate_config(require_s3=True)

    print("\nğŸ“‹ ì„¤ì • ê°’:")
    for key, value in result["config"].items():
        print(f"   {key}: {value}")

    if result["errors"]:
        print("\nâŒ ì˜¤ë¥˜:")
        for error in result["errors"]:
            print(f"   - {error}")

    if result.get("warnings"):
        print("\nâš ï¸ ê²½ê³ :")
        for warning in result["warnings"]:
            print(f"   - {warning}")

    if result["valid"]:
        print("\nâœ… ì„¤ì •ì´ ìœ íš¨í•©ë‹ˆë‹¤!")
    else:
        print("\nâŒ ì„¤ì •ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    return result["valid"]


def test_load_pdf(s3_key: str):
    """S3 PDF ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    from langchain_pipeline.loaders.s3_pdf_loader import S3PDFLoader
    from langchain_pipeline.config import (
        S3_BUCKET_NAME, S3_REGION, GOOGLE_API_KEY,
        AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY
    )

    print("\n" + "=" * 60)
    print("ğŸ“„ S3 PDF ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    loader = S3PDFLoader(
        bucket_name=S3_BUCKET_NAME,
        gemini_api_key=GOOGLE_API_KEY,
        aws_region=S3_REGION,
        aws_access_key_id=AWS_ACCESS_KEY_ID or None,
        aws_secret_access_key=AWS_SECRET_ACCESS_KEY or None,
    )

    print(f"\nğŸ“ S3 Key: {s3_key}")
    print(f"ğŸ“¦ Bucket: {S3_BUCKET_NAME}")

    try:
        gemini_file = loader.load_from_s3(s3_key)

        print(f"\nâœ… Gemini ì—…ë¡œë“œ ì„±ê³µ!")
        print(f"   Name: {gemini_file.name}")
        print(f"   URI: {gemini_file.uri}")
        print(f"   State: {gemini_file.state}")
        print(f"   Display Name: {gemini_file.display_name}")

        # ì •ë¦¬
        loader.delete_file(gemini_file)
        print(f"\nğŸ—‘ï¸ Gemini íŒŒì¼ ì‚­ì œë¨")

        return gemini_file

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        return None


async def test_analyze(s3_key: str, output_file: str = None):
    """êµ¬ì§ì ë¶„ì„ E2E í…ŒìŠ¤íŠ¸"""
    from langchain_pipeline.chains.applicant_chain import ApplicantAnalysisChain

    print("\n" + "=" * 60)
    print("ğŸ¯ êµ¬ì§ì ë¶„ì„ E2E í…ŒìŠ¤íŠ¸ (S3 PDF)")
    print("=" * 60)

    chain = ApplicantAnalysisChain(save_to_db=False)

    try:
        print(f"\nğŸ“ S3 Key: {s3_key}")
        print("â³ ë¶„ì„ ì¤‘... (S3 ë‹¤ìš´ë¡œë“œ â†’ Gemini ì—…ë¡œë“œ â†’ ë¶„ì„)")

        result = await chain.run_from_s3(s3_key)

        print("\nâœ… ë¶„ì„ ì™„ë£Œ!")

        # ìš”ì•½ ì¶œë ¥
        meta = result.get("profile_meta", {})
        print(f"\nğŸ“‹ í”„ë¡œí•„ ìš”ì•½:")
        print(f"   ì´ë¦„: {meta.get('candidate_name', 'N/A')}")
        print(f"   ì—­í• : {meta.get('primary_role', 'N/A')}")
        print(f"   ì—°ì°¨: {meta.get('years_experience', 'N/A')}")

        # ì ìˆ˜ ì¶œë ¥
        axes = result.get("scoring_axes", {})
        print(f"\nğŸ“Š ì»¬ì³í• ì ìˆ˜:")
        for key in ['technical_fit_user', 'execution_style_user', 'collaboration_style_user',
                    'ownership_user', 'growth_orientation_user', 'work_expectation_user']:
            score_data = axes.get(key, {})
            score = score_data.get('score', 'N/A')
            print(f"   - {key}: {score}/4")

        # íŒŒì¼ ì €ì¥ (ì˜µì…˜)
        if output_file:
            output_path = Path(output_file)
            output_path.write_text(
                json.dumps(result, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_path}")

        return result

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

    finally:
        chain.close()


def main():
    parser = argparse.ArgumentParser(description="S3 PDF ë¡œë” í…ŒìŠ¤íŠ¸")

    # ëª¨ë“œ ì„ íƒ
    parser.add_argument("--check-config", action="store_true", help="ì„¤ì • í™•ì¸")
    parser.add_argument("--load-pdf", action="store_true", help="S3 PDF ë¡œë“œ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--analyze", action="store_true", help="êµ¬ì§ì ë¶„ì„ E2E í…ŒìŠ¤íŠ¸")

    # íŒŒë¼ë¯¸í„°
    parser.add_argument("--s3-key", help="S3 ê°ì²´ í‚¤ (ì˜ˆ: token/resume.pdf)")
    parser.add_argument("--output", "-o", help="ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ")

    args = parser.parse_args()

    # ê¸°ë³¸ ë™ì‘: ì„¤ì • í™•ì¸
    if not any([args.check_config, args.load_pdf, args.analyze]):
        args.check_config = True

    if args.check_config:
        check_config()

    if args.load_pdf:
        if not args.s3_key:
            print("âŒ --load-pdfì—ëŠ” --s3-keyê°€ í•„ìš”í•©ë‹ˆë‹¤")
            sys.exit(1)
        test_load_pdf(args.s3_key)

    if args.analyze:
        if not args.s3_key:
            print("âŒ --analyzeì—ëŠ” --s3-keyê°€ í•„ìš”í•©ë‹ˆë‹¤")
            sys.exit(1)
        asyncio.run(test_analyze(args.s3_key, args.output))


if __name__ == "__main__":
    main()
